{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Gaussian parameters using mle\n",
    "def gaussian_mle(trainFile):\n",
    "    # read the trainset file     \n",
    "    fileData = open(trainFile, \"r\",encoding='utf-8-sig')\n",
    "    lines = fileData.readlines()\n",
    "    \n",
    "    # create two matrices for two different classes    \n",
    "    xsClass1 = []\n",
    "    ysClass1 = []\n",
    "    xsClass2 = []\n",
    "    ysClass2 = []\n",
    "\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        xs = float(x[0])\n",
    "        ys = float(x[1])\n",
    "        yc = int(x[2])\n",
    "        if yc == 0:\n",
    "            xsClass1.append(xs)\n",
    "            ysClass1.append(ys)\n",
    "        else:\n",
    "            xsClass2.append(xs)\n",
    "            ysClass2.append(ys)\n",
    "     \n",
    "    # for class0\n",
    "    matClass1 = np.zeros((len(xsClass1), 2))\n",
    "    for i in range(matClass1.shape[0]):\n",
    "        matClass1[i][0] = xsClass1[i]\n",
    "    for i in range(matClass1.shape[0]):\n",
    "        matClass1[i][1] = ysClass1[i]\n",
    "    \n",
    "    # for class1\n",
    "    matClass2 = np.zeros((len(xsClass2), 2))\n",
    "    for i in range(matClass2.shape[0]):\n",
    "        matClass2[i][0] = xsClass2[i]\n",
    "    for i in range(matClass2.shape[0]):\n",
    "        matClass2[i][1] = ysClass2[i]\n",
    "\n",
    "    # find mean vector for class0\n",
    "    m = np.zeros((len(xsClass1), 2))\n",
    "    for i in range(len(matClass1)):\n",
    "        m[i][0] = matClass1[i][0]\n",
    "        m[i][1] = matClass1[i][1]\n",
    "    mu1 = m.sum(axis = 0)/(len(xsClass1)) \n",
    "    mean1 = np.matrix(mu1).T\n",
    "    \n",
    "    # find mean vector for class1\n",
    "    m1 = np.zeros((len(xsClass2), 2))\n",
    "    for i in range(len(matClass2)):\n",
    "        m1[i][0] = matClass2[i][0]\n",
    "        m1[i][1] = matClass2[i][1]\n",
    "    mu2 = m1.sum(axis = 0)/(len(xsClass2)) \n",
    "    mean2 = np.matrix(mu2).T\n",
    "    \n",
    "    # find covariance matrices for class0\n",
    "    sigmaClass1 = np.zeros((len(xsClass1), 2))\n",
    "    cov1 = np.zeros((len(xsClass1), 2))\n",
    "\n",
    "    for i in range(matClass1.shape[0]):\n",
    "        cov1[i][0] = matClass1[i][0]-mu1[0]\n",
    "        cov1[i][1] = matClass1[i][1]-mu1[1]\n",
    "        transposecov1 = np.matrix(cov1).T\n",
    "        sigmaClass1 = transposecov1*cov1/matClass1.shape[0]\n",
    "\n",
    "    # find covariance matrices for class1\n",
    "    sigmaClass2 = np.zeros((len(xsClass2), 2))\n",
    "    cov2 = np.zeros((len(xsClass2), 2))\n",
    "\n",
    "    for i in range(matClass2.shape[0]):\n",
    "        cov2[i][0] = matClass2[i][0]-mu2[0]\n",
    "        cov2[i][1] = matClass2[i][1]-mu2[1]\n",
    "        transposecov2 = np.matrix(cov2).T\n",
    "        sigmaClass2 = transposecov2*cov2/matClass2.shape[0]   \n",
    "        \n",
    "    return mean1, mean2, sigmaClass1, sigmaClass2\n",
    "\n",
    "# uncomment this line for output\n",
    "# gaussian_mle(\"SYNTH.TR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create three dictionaries to store the important results of three cases for further visualizations\n",
    "bestAccuracy_dict1 = dict()\n",
    "bestAccuracy_dict2 = dict()\n",
    "bestAccuracy_dict3 = dict()\n",
    "predictedMatrix_dict = dict()  \n",
    "\n",
    "# uncomment to clear the dictionary if necessary\n",
    "# bestAccuracy_dict1.clear()\n",
    "# bestAccuracy_dict2.clear()\n",
    "# bestAccuracy_dict3.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean1,mean2,sigmaClass1,sigmaClass2  = gaussian_mle(\"SYNTH.TR\")\n",
    "\n",
    "# calculate for different probabilities and create dictionary with probability as keys and accuracy as values\n",
    "def mpp(testFile, probClass1,mean1,mean2,sigma1,sigma2,sigmaSqr):\n",
    "    probClass2 = 1-probClass1\n",
    "    \n",
    "    # read the test data file\n",
    "    fileData1 = open(testFile, \"r\",encoding='utf-8-sig')\n",
    "    liness = fileData1.readlines()\n",
    "    \n",
    "    # create a matrix from test data for calculation\n",
    "    testSet = np.zeros((len(liness),3))\n",
    "    xst = []\n",
    "    yst = []\n",
    "    yct = []\n",
    "    for line in liness:\n",
    "        xt = line.split()\n",
    "        xst.append(float(xt[0]))\n",
    "        yst.append(float(xt[1]))\n",
    "        yct.append(int(xt[2]))\n",
    "    for i in range(len(liness)):\n",
    "        testSet[i][0] = xst[i]\n",
    "        testSet[i][1] = yst[i]\n",
    "        testSet[i][2] = yct[i]\n",
    " \n",
    "    # find covariance matrices for CASE I\n",
    "    I = np.identity(2)\n",
    "    sigma3 = sigmaSqr*I\n",
    "\n",
    "    # calculate determinant and inverse of new covariance Matrix (case 1: covariance matrices are equal to (sigma^2)I)\n",
    "    detClass1 = np.linalg.det(sigma3)\n",
    "    detClass2 = detClass1\n",
    "    invClass1 = np.linalg.inv(sigma3)\n",
    "    invClass2 = invClass1\n",
    "\n",
    "    # test the three cases of discriminant analysis for best accuracy\n",
    "    LAMBDA11 = 0\n",
    "    LAMBDA12 = 1\n",
    "    LAMBDA21 = 1\n",
    "    LAMBDA22 = 0\n",
    "\n",
    "    testCase = 0\n",
    "    while testCase < 3:\n",
    "        bestLambda1 = 1.0\n",
    "        bestLambda2 = 1.0\n",
    "        bestAccuracy = 0\n",
    "\n",
    "        lambdaClass1 = 1.0\n",
    "        while lambdaClass1 > 0:\n",
    "            bestLambda1 = 1.0\n",
    "            bestLambda2 = 1.0\n",
    "            bestAccuracy = 0\n",
    "\n",
    "            lambdaClass2 = 1.0\n",
    "            while lambdaClass2 > 0:\n",
    "                predictedMatrix = np.zeros((len(testSet), 2))\n",
    "                correctGuesses = 0\n",
    "                line1 = np.zeros((1, 2))\n",
    "                for i in range(len(testSet)):\n",
    "                    line1[:,0] = testSet[i][0]\n",
    "                    line1[:,1] = testSet[i][1]\n",
    "                    line2 = line1.T\n",
    "                    mahalanobis = line2 - mean1\n",
    "                    mahalanobis1 = mahalanobis.T\n",
    "                    mahalanobis2 = mahalanobis1 * invClass1\n",
    "                    mahalanobis3 = mahalanobis2 * (line2 - mean1)\n",
    "                    varMahalanobis = float(-0.5 * mahalanobis3[0][0])\n",
    "                    probIsClass1 = float((1.0 / math.sqrt(2 * math.pi * detClass1)) * math.exp(varMahalanobis) * (probClass1))\n",
    "\n",
    "                    mahalanobiss = line2 - mean2\n",
    "                    mahalanobiss1 = mahalanobiss.T\n",
    "                    mahalanobiss2 = mahalanobiss1 * invClass2\n",
    "                    mahalanobiss3 = mahalanobiss2 * (line2 - mean2)\n",
    "                    varMahalanobiss = float(-0.5 * mahalanobiss3[0][0])\n",
    "\n",
    "                    probIsClass2 = float((1.0 / math.sqrt(2 * math.pi * detClass2)) * math.exp(varMahalanobiss) * (probClass2))\n",
    "\n",
    "                    aux = float(probIsClass1)\n",
    "                    probIsClass1 = lambdaClass1 * probIsClass1 + (1 - lambdaClass1) * probIsClass2\n",
    "                    probIsClass2 = lambdaClass2 * probIsClass2 + (1 - lambdaClass2) * aux\n",
    "\n",
    "                    predictedClass = 0\n",
    "                    if probIsClass2 > probIsClass1:\n",
    "                        predictedClass = 1\n",
    "\n",
    "                    if predictedClass == testSet[i][2]: \n",
    "                        correctGuesses+=1\n",
    "\n",
    "                    error = float(min(probIsClass2, probIsClass1))\n",
    "\n",
    "                    predictedMatrix[i][1] = error\n",
    "                    predictedMatrix[i][0] = predictedClass\n",
    "\n",
    "                acc = float(correctGuesses) / float(len(testSet))\n",
    "                if acc > bestAccuracy:\n",
    "                    bestAccuracy = acc\n",
    "                    bestLambda1 = lambdaClass1\n",
    "                    bestLambda2 = lambdaClass2\n",
    "                lambdaClass2 -= 0.05\n",
    "            lambdaClass1 -= 0.05\n",
    "\n",
    "        if testCase == 0:\n",
    "            print (\"Discriminant Function Case 1 (features independents): accuracy = \",bestAccuracy,\n",
    "                   \"with probability\",probClass1,\"and\",probClass2, \"Lambda1,1=\",bestLambda1,\";Lambda1,2=\",\n",
    "                   1 - bestLambda1,\";Lambda2,1=\",bestLambda2,\";Lambda2,2=\",(1 - bestLambda2))\n",
    "            acc1 = bestAccuracy\n",
    "\n",
    "            # calculate determinant and inverse of new covariance matrices (case 2: covariance matrices is equal)\n",
    "            detClass1 = np.linalg.det(sigma1)\n",
    "            detClass2 = detClass1\n",
    "            invClass1 = np.linalg.inv(sigma1)\n",
    "            invClass2 = invClass1\n",
    "\n",
    "        elif testCase == 1:\n",
    "            print (\"Discriminant Function Case 2 (covariance matrix equal for all features): accuracy = \",\n",
    "                   bestAccuracy,\"with probability\",probClass1,\"and\",probClass2,\" Lambda1,1=\",bestLambda1,\n",
    "                   \";Lambda1,1=\",bestLambda1,\";Lambda1,2=\",1-bestLambda1,\";Lambda2,1=\",bestLambda2,\";Lambda2,2=\",\n",
    "                   (1 - bestLambda2))\n",
    "            acc2 = bestAccuracy\n",
    "\n",
    "            # calculate determinant and inverse of new covariance matrices (case 3: covariance matrices are different)\n",
    "            detClass1 = np.linalg.det(sigma1)\n",
    "            invClass1 = np.linalg.inv(sigma1)\n",
    "            invClass2 = np.linalg.inv(sigma2)\n",
    "            detClass2 = np.linalg.det(sigma2)\n",
    "\n",
    "        elif testCase == 2:\n",
    "            print (\"Discriminant Function Case 3 (arbitrary): accuracy = \", bestAccuracy,\n",
    "                   \"with probability\",probClass1,\"and\",probClass2,\" Lambda1,1=\",bestLambda1 , \";Lambda1,2=\" \n",
    "                   , (1 - bestLambda1),\";Lambda2,1=\" , bestLambda2 ,\";Lambda2,2=\", (1 - bestLambda2))\n",
    "            acc3 = bestAccuracy\n",
    "\n",
    "        testCase+=1\n",
    "    bestAccuracy_dict1[probClass1]= acc1\n",
    "    bestAccuracy_dict2[probClass1]= acc2\n",
    "    bestAccuracy_dict3[probClass1]= acc3\n",
    "    return bestAccuracy_dict1,bestAccuracy_dict2,bestAccuracy_dict3\n",
    "\n",
    "# uncomment this line for output\n",
    "# mpp(\"SYNTH.TE\", 0.5,mean1,mean2,sigmaClass1,sigmaClass2,sigmaClass1[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kept the result for convenience\n",
    "bestAccuracy_dict1={0.1: 0.735, 0.2: 0.723, 0.3: 0.708, 0.4: 0.704, 0.5: 0.713, 0.6: 0.714, 0.7: 0.709, 0.8: 0.714, 0.9: 0.706}\n",
    "bestAccuracy_dict2={0.1: 0.751, 0.2: 0.827, 0.3: 0.867, 0.4: 0.886, 0.5: 0.885, 0.6: 0.879, 0.7: 0.859, 0.8: 0.816, 0.9: 0.723}\n",
    "bestAccuracy_dict3={0.1: 0.799, 0.2: 0.851, 0.3: 0.874, 0.4: 0.887, 0.5: 0.898, 0.6: 0.89, 0.7: 0.868, 0.8: 0.83, 0.9: 0.747}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mle(dict1, dict2, dict3):\n",
    "    # extract keys and values from the dictionaries and keep them into lists\n",
    "    x = []\n",
    "    y = []\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "    x2 = []\n",
    "    y2 = []\n",
    "\n",
    "    for data in dict1.keys():\n",
    "        x.append(data)\n",
    "    for data in dict1.values():\n",
    "        y.append(data)\n",
    "\n",
    "    for data in dict2.keys():\n",
    "        x1.append(data)\n",
    "    for data in dict2.values():\n",
    "        y1.append(data)\n",
    "\n",
    "    for data in dict3.keys():\n",
    "        x2.append(data)\n",
    "    for data in dict3.values():\n",
    "        y2.append(data)\n",
    "        \n",
    "    # plot accuracy with respect to prior probability of class0 \n",
    "    plt.figure(figsize=(10,8))\n",
    "    line1 = plt.plot(x, y,'ko-',label='Case I')\n",
    "    line2 = plt.plot(x1, y1,'ro-',label='Case II') \n",
    "    line3 = plt.plot(x2, y2,'mo-',label='Case III')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Prior probabilities for Class1')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Performance Analysis for Different Prior Probability Distributions')\n",
    "    \n",
    "# uncomment this line for output\n",
    "# plot_mle (bestAccuracy_dict1,bestAccuracy_dict2,bestAccuracy_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter Estimation using Bayesian Learning for Whole Sample\n",
    "def bayesian_learning_all(trainFile):\n",
    "    # read the trainset file     \n",
    "    fileData = open(trainFile, \"r\",encoding='utf-8-sig')\n",
    "    lines = fileData.readlines()\n",
    "    \n",
    "    xsClass = []\n",
    "    ysClass = []\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        xs = float(x[0])\n",
    "        ys = float(x[1])\n",
    "        yc = int(x[2])\n",
    "        xsClass.append(xs)\n",
    "        ysClass.append(ys)\n",
    "        \n",
    "    matClass = np.zeros((len(xsClass), 2))\n",
    "    for i in range(matClass.shape[0]):\n",
    "        matClass[i][0] = xsClass[i]\n",
    "    for i in range(matClass.shape[0]):\n",
    "        matClass[i][1] = ysClass[i]\n",
    "\n",
    "    # sample mean and covariance\n",
    "    mean = np.mean(matClass,axis=0)\n",
    "    meanClass = np.matrix(mean).T\n",
    "    \n",
    "    sigmaClass = np.zeros((len(xsClass), 2))\n",
    "    cov = np.zeros((len(xsClass), 2))\n",
    "    for i in range(matClass.shape[0]):\n",
    "        cov[i][0] = matClass[i][0]-mean[0]\n",
    "        cov[i][1] = matClass[i][1]-mean[1]\n",
    "        transposecov = np.matrix(cov).T\n",
    "        sigmaClass = transposecov*cov/matClass.shape[0]\n",
    "\n",
    "    # guess values for mean and covariance\n",
    "    meanGuess = np.matrix('0.01 0.44').T\n",
    "    sigmaGuess = np.matrix('0.2 0.02;0.02 0.06')\n",
    "    \n",
    "    # find mean vector \n",
    "    n = len(matClass)\n",
    "    bayesMeanPart1 = sigmaGuess*np.linalg.inv(sigmaGuess+(1/n)*sigmaClass)*meanClass\n",
    "    bayesMeanPart2 = (1/n)*sigmaClass*np.linalg.inv(sigmaGuess+(1/n)*sigmaClass)*meanGuess\n",
    "    bayesMean = bayesMeanPart1+bayesMeanPart2\n",
    "\n",
    "    # find covariance\n",
    "    bayesVar = sigmaGuess*np.linalg.inv(sigmaGuess+(1/n)*sigmaClass)*(1/n)*sigmaClass\n",
    "    \n",
    "    return bayesMean, bayesVar\n",
    "\n",
    "# uncomment for output\n",
    "# bayesian_learning_all (\"SYNTH.TR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_learning(trainFile):\n",
    "    # read the trainset file     \n",
    "    fileData = open(trainFile, \"r\",encoding='utf-8-sig')\n",
    "    lines = fileData.readlines()\n",
    "    \n",
    "    # create two matrices for two different classes    \n",
    "    xsClass1 = []\n",
    "    ysClass1 = []\n",
    "    xsClass2 = []\n",
    "    ysClass2 = []\n",
    "\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        xs = float(x[0])\n",
    "        ys = float(x[1])\n",
    "        yc = int(x[2])\n",
    "        if yc == 0:\n",
    "            xsClass1.append(xs)\n",
    "            ysClass1.append(ys)\n",
    "        else:\n",
    "            xsClass2.append(xs)\n",
    "            ysClass2.append(ys)\n",
    "     \n",
    "    # for class0\n",
    "    matClass1 = np.zeros((len(xsClass1), 2))\n",
    "    for i in range(matClass1.shape[0]):\n",
    "        matClass1[i][0] = xsClass1[i]\n",
    "    for i in range(matClass1.shape[0]):\n",
    "        matClass1[i][1] = ysClass1[i]\n",
    "    \n",
    "    # for class1\n",
    "    matClass2 = np.zeros((len(xsClass2), 2))\n",
    "    for i in range(matClass2.shape[0]):\n",
    "        matClass2[i][0] = xsClass2[i]\n",
    "    for i in range(matClass2.shape[0]):\n",
    "        matClass2[i][1] = ysClass2[i]\n",
    "\n",
    "    # sample mean for class0\n",
    "    mean1 = np.mean(matClass1,axis=0)\n",
    "    meanClass1 = np.matrix(mean1).T\n",
    "    \n",
    "    # sample mean for class1\n",
    "    mean2 = np.mean(matClass2,axis=0)\n",
    "    meanClass2 = np.matrix(mean2).T\n",
    "\n",
    "    # sample covariance for class0\n",
    "    sigmaClass1 = np.zeros((len(xsClass1), 2))\n",
    "    cov1 = np.zeros((len(xsClass1), 2))\n",
    "    for i in range(matClass1.shape[0]):\n",
    "        cov1[i][0] = matClass1[i][0]-mean1[0]\n",
    "        cov1[i][1] = matClass1[i][1]-mean1[1]\n",
    "        transposecov1 = np.matrix(cov1).T\n",
    "        sigmaClass1 = transposecov1*cov1/matClass1.shape[0]\n",
    "\n",
    "    # sample covariance for class1\n",
    "    sigmaClass2 = np.zeros((len(xsClass1), 2))\n",
    "    cov2 = np.zeros((len(xsClass1), 2))\n",
    "    for i in range(matClass2.shape[0]):\n",
    "        cov2[i][0] = matClass2[i][0]-mean2[0]\n",
    "        cov2[i][1] = matClass2[i][1]-mean2[1]\n",
    "        transposecov2 = np.matrix(cov2).T\n",
    "        sigmaClass2 = transposecov2*cov2/matClass2.shape[0]\n",
    "        \n",
    "    # guess values for mean and covariance\n",
    "    meanGuess1 = np.matrix('0.01 0.44').T\n",
    "    sigmaGuess1 = np.matrix('0.02 0.002;0.002 0.006')\n",
    "    meanGuess2 = np.matrix('0.02 0.3').T\n",
    "    sigmaGuess2 = np.matrix('0.02 0.01;0.01 0.05')\n",
    "    \n",
    "    n = len(matClass1)\n",
    "    commonPart1 = sigmaGuess1+(1/n)*sigmaClass1\n",
    "    commonPart2 = sigmaGuess2+(1/n)*sigmaClass2\n",
    "\n",
    "    # find mean vector for class0\n",
    "    bayesMeanPart1 = sigmaGuess1*np.linalg.inv(commonPart1)*meanClass1\n",
    "    bayesMeanPart2 = (1/n)*sigmaClass1*np.linalg.inv(commonPart1)*meanGuess1\n",
    "    bayesMean1 = bayesMeanPart1+bayesMeanPart2\n",
    "\n",
    "    # find mean vector for class1\n",
    "    bayesMeanPart1a = sigmaGuess2*np.linalg.inv(commonPart2)*meanClass2\n",
    "    bayesMeanPart2a = (1/n)*sigmaClass2*np.linalg.inv(commonPart2)*meanGuess2\n",
    "    bayesMean2 = bayesMeanPart1a+bayesMeanPart2a\n",
    "\n",
    "    # find covariance for class 0\n",
    "    bayesVar1 = sigmaGuess1*np.linalg.inv(commonPart1)*(1/n)*sigmaClass1\n",
    "    \n",
    "    # find covariance for class 1\n",
    "    bayesVar2 = sigmaGuess2*np.linalg.inv(commonPart2)*(1/n)*sigmaClass2\n",
    "    \n",
    "    return bayesMean1, bayesMean2, bayesVar1, bayesVar2\n",
    "\n",
    "# uncomment for output\n",
    "# bayesian_learning (\"SYNTH.TR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesMean1,bayesMean2,bayesVar1,bayesVar2  = bayesian_learning(\"SYNTH.TR\")\n",
    "# print (bayesian_learning(\"SYNTH.TR\"))\n",
    "\n",
    "# calculate for different probabilities and create dictionary with probability as keys and accuracy as values\n",
    "def mpp(testFile, probClass1,mean1,mean2,sigma1,sigma2,sigmaSqr):\n",
    "    probClass2 = 1-probClass1\n",
    "    \n",
    "    # read the test data file\n",
    "    fileData1 = open(testFile, \"r\",encoding='utf-8-sig')\n",
    "    liness = fileData1.readlines()\n",
    "    \n",
    "    # create a matrix from test data for calculation\n",
    "    testSet = np.zeros((len(liness),3))\n",
    "    xst = []\n",
    "    yst = []\n",
    "    yct = []\n",
    "    for line in liness:\n",
    "        xt = line.split()\n",
    "        xst.append(float(xt[0]))\n",
    "        yst.append(float(xt[1]))\n",
    "        yct.append(int(xt[2]))\n",
    "    for i in range(len(liness)):\n",
    "        testSet[i][0] = xst[i]\n",
    "        testSet[i][1] = yst[i]\n",
    "        testSet[i][2] = yct[i]\n",
    "        \n",
    "    # find covariance matrices for CASE I\n",
    "    I = np.identity(2)\n",
    "    sigma3 = sigmaSqr*I\n",
    "\n",
    "    # calculate determinant and inverse of new covariance Matrix (case 1: covariance matrices are equal to (sigma^2)I)\n",
    "    detClass1 = np.linalg.det(sigma3)\n",
    "    detClass2 = detClass1\n",
    "    invClass1 = np.linalg.inv(sigma3)\n",
    "    invClass2 = invClass1\n",
    "\n",
    "    # test the three cases of discriminant analysis for best accuracy\n",
    "    LAMBDA11 = 0\n",
    "    LAMBDA12 = 1\n",
    "    LAMBDA21 = 1\n",
    "    LAMBDA22 = 0\n",
    "\n",
    "    testCase = 0\n",
    "    while testCase < 3:\n",
    "        bestLambda1 = 1.0\n",
    "        bestLambda2 = 1.0\n",
    "        bestAccuracy = 0\n",
    "\n",
    "        lambdaClass1 = 1.0\n",
    "        while lambdaClass1 > 0:\n",
    "            bestLambda1 = 1.0\n",
    "            bestLambda2 = 1.0\n",
    "            bestAccuracy = 0\n",
    "\n",
    "            lambdaClass2 = 1.0\n",
    "            while lambdaClass2 > 0:\n",
    "                predictedMatrix = np.zeros((len(testSet), 2))\n",
    "                correctGuesses = 0\n",
    "                line1 = np.zeros((1, 2))\n",
    "                for i in range(len(testSet)):\n",
    "                    line1[:,0] = testSet[i][0]\n",
    "                    line1[:,1] = testSet[i][1]\n",
    "                    line2 = line1.T\n",
    "                    mahalanobis = line2 - mean1\n",
    "                    mahalanobis1 = mahalanobis.T\n",
    "                    mahalanobis2 = mahalanobis1 * invClass1\n",
    "                    mahalanobis3 = mahalanobis2 * (line2 - mean1)\n",
    "                    varMahalanobis = float(-0.5 * mahalanobis3[0][0])\n",
    "                    probIsClass1 = float((1.0 / math.sqrt(2 * math.pi * detClass1)) * math.exp(varMahalanobis) * (probClass1))\n",
    "\n",
    "                    mahalanobiss = (line2 - mean2)\n",
    "                    mahalanobiss1 = mahalanobiss.T\n",
    "                    mahalanobiss2 = mahalanobiss1 * invClass2\n",
    "                    mahalanobiss3 = mahalanobiss2 * (line2 - mean2)\n",
    "                    varMahalanobiss = float(-0.5 * mahalanobiss3[0][0])\n",
    "\n",
    "                    probIsClass2 = float((1.0 / math.sqrt(2 * math.pi * detClass2)) * math.exp(varMahalanobiss) * (probClass2))\n",
    "\n",
    "                    aux = float(probIsClass1)\n",
    "                    probIsClass1 = lambdaClass1 * probIsClass1 + (1 - lambdaClass1) * probIsClass2\n",
    "                    probIsClass2 = lambdaClass2 * probIsClass2 + (1 - lambdaClass2) * aux\n",
    "\n",
    "                    predictedClass = 0\n",
    "                    if probIsClass2 > probIsClass1:\n",
    "                        predictedClass = 1\n",
    "\n",
    "                    if predictedClass == testSet[i][2]: \n",
    "                        correctGuesses+=1\n",
    "\n",
    "                    error = float(min(probIsClass2, probIsClass1))\n",
    "\n",
    "                    predictedMatrix[i][1] = error\n",
    "                    predictedMatrix[i][0] = predictedClass\n",
    "\n",
    "                acc = float(correctGuesses) / float(len(testSet))\n",
    "                if acc > bestAccuracy:\n",
    "                    bestAccuracy = acc\n",
    "                    bestLambda1 = lambdaClass1\n",
    "                    bestLambda2 = lambdaClass2\n",
    "                lambdaClass2 -= 0.05\n",
    "            lambdaClass1 -= 0.05\n",
    "\n",
    "        if testCase == 0:\n",
    "            print (\"Discriminant Function Case 1 (features independents): accuracy = \",bestAccuracy,\n",
    "                   \"with probability\",probClass1,\"and\",probClass2, \"Lambda1,1=\",bestLambda1,\";Lambda1,2=\",\n",
    "                   1 - bestLambda1,\";Lambda2,1=\",bestLambda2,\";Lambda2,2=\",(1 - bestLambda2))\n",
    "\n",
    "            # calculate determinant and inverse of new covariance matrices (case 2: covariance matrices is equal)\n",
    "            detClass1 = np.linalg.det(sigma1)\n",
    "            detClass2 = detClass1\n",
    "            invClass1 = np.linalg.inv(sigma1)\n",
    "            invClass2 = invClass1\n",
    "\n",
    "        elif testCase == 1:\n",
    "            print (\"Discriminant Function Case 2 (covariance matrix equal for all features): accuracy = \",\n",
    "                   bestAccuracy,\"with probability\",probClass1,\"and\",probClass2,\" Lambda1,1=\",bestLambda1,\n",
    "                   \";Lambda1,1=\",bestLambda1,\";Lambda1,2=\",1-bestLambda1,\";Lambda2,1=\",bestLambda2,\";Lambda2,2=\",\n",
    "                   (1 - bestLambda2))\n",
    "\n",
    "            # calculate determinant and inverse of new covariance matrices (case 3: covariance matrices are different)\n",
    "            detClass1 = np.linalg.det(sigma1)\n",
    "            invClass1 = np.linalg.inv(sigma1)\n",
    "            invClass2 = np.linalg.inv(sigma2)\n",
    "            detClass2 = np.linalg.det(sigma2)\n",
    "\n",
    "        elif testCase == 2:\n",
    "            print (\"Discriminant Function Case 3 (arbitrary): accuracy = \", bestAccuracy,\n",
    "                   \"with probability\",probClass1,\"and\",probClass2,\" Lambda1,1=\",bestLambda1 , \";Lambda1,2=\" \n",
    "                   , (1 - bestLambda1),\";Lambda2,1=\" , bestLambda2 ,\";Lambda2,2=\", (1 - bestLambda2))\n",
    "\n",
    "        testCase+=1\n",
    "\n",
    "# uncomment for output\n",
    "# mpp(\"SYNTH.TE\", 0.5,bayesMean1,bayesMean2,bayesVar1,bayesVar2,bayesVar2[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for plotting\n",
    "Bayesian_dict = {'Case I':0.723 , 'Case II': 0.888,'Case III':0.89 }\n",
    "MLE_dict = {'Case I': 0.713,'Case II':0.885,'Case III':0.89}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bayes_mle(dict1, dict2):\n",
    "    # extract keys and values from the dictionaries and keep them into lists\n",
    "    x = []\n",
    "    y = []\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "\n",
    "    for data in dict1.keys():\n",
    "        x.append(data)\n",
    "    for data in dict1.values():\n",
    "        y.append(data)\n",
    "\n",
    "    for data in dict2.keys():\n",
    "        x1.append(data)\n",
    "    for data in dict2.values():\n",
    "        y1.append(data)\n",
    "        \n",
    "    # plot accuracy with respect to 3 cases \n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(1,1,figsize=(8,5))\n",
    "    opacity = .7\n",
    "    w = .3\n",
    "    \n",
    "    a1 = [x for x, _ in enumerate(x)]\n",
    "    b1 = [x + w for x in a1]\n",
    "\n",
    "    axs.bar(a1, y, color='red', width=w, edgecolor='white', label='Bayesian Learnning')\n",
    "    axs.bar(b1, y1, color='yellowgreen', width=w, edgecolor='white', label='MLE')\n",
    "\n",
    "    plt.xticks([x + w for x in range(len(x))], x)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Three Cases of Discriminant Analysis')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Performance Analysis of Bayesian Learning & MLE with Prior Probability 0.5 Each')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# uncomment for output\n",
    "# plot_bayes_mle (Bayesian_dict,MLE_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bimodal(testFile, probClass1, a1):\n",
    "    fileData1 = open(testFile, \"r\",encoding='utf-8-sig')\n",
    "    liness = fileData1.readlines()\n",
    "    \n",
    "    # create a matrix from test data for calculation\n",
    "    testSet = np.zeros((len(liness),3))\n",
    "    xst = []\n",
    "    yst = []\n",
    "    yct = []\n",
    "    for line in liness:\n",
    "        xt = line.split()\n",
    "        xst.append(float(xt[0]))\n",
    "        yst.append(float(xt[1]))\n",
    "        yct.append(int(xt[2]))\n",
    "    for i in range(len(liness)):\n",
    "        testSet[i][0] = xst[i]\n",
    "        testSet[i][1] = yst[i]\n",
    "        testSet[i][2] = yct[i]\n",
    "    \n",
    "    mean1 = np.matrix('-.75 .2')\n",
    "    mean2 = np.matrix('-.23 .79')\n",
    "\n",
    "    sigmaClass1 = np.matrix('0.25 0; 0 0.3')\n",
    "    sigmaClass2 = np.matrix('.07 .021 ; .021 0.047')\n",
    "\n",
    "\n",
    "    meanex = np.matrix('0.3 0.3')                #extra mean for class 0 \n",
    "    covex = np.matrix('.1 0 ; 0 0.01')    #extra variance for class 0\n",
    "\n",
    "    meanex1 = np.matrix('0.55 0.69')               #extra mean for class 1\n",
    "    covex1 = np.matrix('.049 .055; .055 .089')   #extra variance for class 1\n",
    "\n",
    "    I = np.identity(2)\n",
    "    sigma3 = sigmaClass1[0,0]*I\n",
    "    \n",
    "    # calculate determinant and inverse of new covariance Matrix (case 1: covariance matrices are equal to (sigma^2)I)\n",
    "    detClass1 = np.linalg.det(sigma3)\n",
    "    detClass2 = detClass1\n",
    "    invClass1 = np.linalg.inv(sigma3)\n",
    "    invClass2 = invClass1\n",
    "\n",
    "    # test the three cases of discriminant analysis for best accuracy\n",
    "    LAMBDA11 = 0\n",
    "    LAMBDA12 = 1\n",
    "    LAMBDA21 = 1\n",
    "    LAMBDA22 = 0\n",
    "\n",
    "    d = 2\n",
    "    a2 = 1-a1\n",
    "    probClass2 = 1-probClass1\n",
    "\n",
    "\n",
    "    detClass1 = np.linalg.det(sigma3)\n",
    "    detClass2 = detClass1\n",
    "    detcovex = detClass1\n",
    "    detcovex1 = detClass1\n",
    "\n",
    "    invClass1 = np.linalg.inv(sigma3)\n",
    "    invClass2 = invClass1\n",
    "    invcovex = invClass1\n",
    "    invcovex1 = invClass1\n",
    "\n",
    "\n",
    "    testCase = 0\n",
    "    while testCase < 3:\n",
    "        bestLambda1 = 1.0\n",
    "        bestLambda2 = 1.0\n",
    "        bestAccuracy = 0\n",
    "\n",
    "        lambdaClass1 = 1.0\n",
    "        while lambdaClass1 > 0:\n",
    "            bestLambda1 = 1.0\n",
    "            bestLambda2 = 1.0\n",
    "            bestAccuracy = 0\n",
    "\n",
    "            lambdaClass2 = 1.0\n",
    "            while lambdaClass2 > 0:\n",
    "                predictedMatrix = np.zeros((len(testSet), 2))\n",
    "                correctGuesses = 0\n",
    "                line1 = np.zeros((1, 2))\n",
    "                for i in range(len(testSet)):\n",
    "                    line1[:,0] = testSet[i][0]\n",
    "                    line1[:,1] = testSet[i][1]\n",
    "                    line2 = line1.T\n",
    "                    mahalanobis = line2 - (mean1).T\n",
    "                    mahalanobis1 = mahalanobis.T\n",
    "                    mahalanobis2 = mahalanobis1 * invClass1\n",
    "                    mahalanobis3 = mahalanobis2 * (line2 - (mean1).T)\n",
    "                    varMahalanobis = float(-0.5 * mahalanobis3[0][0])\n",
    "\n",
    "                    mahalanobisex = line2 - (meanex).T\n",
    "                    mahalanobis1ex = mahalanobisex.T\n",
    "                    mahalanobis2ex = mahalanobis1ex * invcovex\n",
    "                    mahalanobis3ex = mahalanobis2ex * (line2 - (meanex).T)\n",
    "                    varMahalanobisx = float(-0.5 * mahalanobis3ex[0][0])\n",
    "\n",
    "                    # bimodal pdf\n",
    "                    probIsClass1 = float(a1*(1.0 / (((2 * math.pi)**(d/2) )* math.sqrt(detClass1))) * math.exp(varMahalanobis) * (probClass1) +\n",
    "                                        a2*(1.0 / (((2 * math.pi)**(d/2)) * math.sqrt(detcovex))) * math.exp(varMahalanobisx) * (probClass1))\n",
    "\n",
    "\n",
    "                    mahalanobiss = line2 - (mean2).T\n",
    "                    mahalanobiss1 = mahalanobiss.T\n",
    "                    mahalanobiss2 = mahalanobiss1 * invClass2\n",
    "                    mahalanobiss3 = mahalanobiss2 * (line2 - (mean2).T)\n",
    "                    varMahalanobiss = float(-0.5 * mahalanobiss3[0][0])\n",
    "\n",
    "                    mahalanobisex1 = line2 - (meanex1).T\n",
    "                    mahalanobis1ex1 = mahalanobisex1.T\n",
    "                    mahalanobis2ex1 = mahalanobis1ex1 * invcovex1\n",
    "                    mahalanobis3ex1 = mahalanobis2ex1 * (line2 - (meanex1).T)\n",
    "                    varMahalanobisx1 = float(-0.5 * mahalanobis3ex1[0][0])\n",
    "\n",
    "                    probIsClass2 = float(a1*(1.0 / (((2 * math.pi)**(d/2)) * math.sqrt(detClass2))) * math.exp(varMahalanobiss) * (probClass2) +\n",
    "                                        a2*(1.0 / (((2 * math.pi)**(d/2)) * math.sqrt(detcovex1))) * math.exp(varMahalanobisx1) * (probClass2))\n",
    "\n",
    "                    aux = float(probIsClass1)\n",
    "                    probIsClass1 = lambdaClass1 * probIsClass1 + (1 - lambdaClass1) * probIsClass2\n",
    "                    probIsClass2 = lambdaClass2 * probIsClass2 + (1 - lambdaClass2) * aux\n",
    "\n",
    "                    predictedClass = 0\n",
    "                    if probIsClass2 > probIsClass1:\n",
    "                        predictedClass = 1\n",
    "\n",
    "                    if predictedClass == testSet[i][2]: \n",
    "                        correctGuesses+=1\n",
    "\n",
    "                    error = float(min(probIsClass2, probIsClass1))\n",
    "\n",
    "                    predictedMatrix[i][1] = error\n",
    "                    predictedMatrix[i][0] = predictedClass\n",
    "\n",
    "                acc = float(correctGuesses) / float(len(testSet))\n",
    "                if acc > bestAccuracy:\n",
    "                    bestAccuracy = acc\n",
    "                    bestLambda1 = lambdaClass1\n",
    "                    bestLambda2 = lambdaClass2\n",
    "                lambdaClass2 -= 0.05\n",
    "            lambdaClass1 -= 0.05\n",
    "\n",
    "        if testCase == 0:\n",
    "            print (\"Discriminant Function Case 1 (features independents): accuracy = \",bestAccuracy,\n",
    "                   \"with probability\",probClass1,\"and\",probClass2, \"Lambda1,1=\",\n",
    "                   bestLambda1,\";Lambda1,2=\",1 - bestLambda1,\";Lambda2,1=\",bestLambda2,\";Lambda2,2=\",\n",
    "                   (1 - bestLambda2))\n",
    "            acc1 = bestAccuracy\n",
    "\n",
    "            detClass1 = np.linalg.det(covex)\n",
    "            detClass2 = detClass1\n",
    "            detcovex = detClass1\n",
    "            detcovex1 = detClass1\n",
    "            invClass1 = np.linalg.inv(covex)\n",
    "            invClass2 = invClass1\n",
    "            invcovex = invClass1\n",
    "            invcovex1 = invClass1\n",
    "\n",
    "        elif testCase == 1:\n",
    "            print (\"Discriminant Function Case 2 (covariance matrix equal for all features): accuracy = \",\n",
    "                   bestAccuracy,\"with probability\",probClass1,\"and\",probClass2,\n",
    "                   \" Lambda1,1=\",bestLambda1,\";Lambda1,2=\",\n",
    "                   1-bestLambda1,\";Lambda2,1=\",bestLambda2,\";Lambda2,2=\",(1 - bestLambda2))\n",
    "            acc2 = bestAccuracy\n",
    "\n",
    "            detClass1 = np.linalg.det(sigmaClass1)\n",
    "            invClass1 = np.linalg.inv(sigmaClass1)\n",
    "            invClass2 = np.linalg.inv(sigmaClass2)\n",
    "            detClass2 = np.linalg.det(sigmaClass2)\n",
    "            detcovex = np.linalg.det(covex)\n",
    "            invcovex = np.linalg.inv(covex)\n",
    "            detcovex1 = np.linalg.det(covex1)\n",
    "            invcovex1 = np.linalg.inv(covex1)\n",
    "\n",
    "\n",
    "        elif testCase == 2:\n",
    "            print (\"Discriminant Function Case 3 (arbitrary): accuracy = \", bestAccuracy,\n",
    "                   \"with probability\",probClass1,\"and\",probClass2,\" Lambda1,1=\",\n",
    "                   bestLambda1 , \";Lambda1,2=\" , (1 - bestLambda1),\";Lambda2,1=\" , bestLambda2 , \n",
    "                   \";Lambda2,2=\", (1 - bestLambda2))\n",
    "            acc3 = bestAccuracy\n",
    "\n",
    "        testCase+=1\n",
    "\n",
    "# uncomment this line for output\n",
    "# bimodal('SYNTH.TE',0.5, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for plotting\n",
    "bimodal_dict = {'Case I': 0.777, 'Case II': 0.886,'Case III': 0.9}\n",
    "unimodal_dict = {'Case I': 0.713,'Case II':0.885,'Case III':0.898}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_modal(dict1, dict2):\n",
    "    # extract keys and values from the dictionaries and keep them into lists\n",
    "    x = []\n",
    "    y = []\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "\n",
    "    for data in dict1.keys():\n",
    "        x.append(data)\n",
    "    for data in dict1.values():\n",
    "        y.append(data)\n",
    "\n",
    "    for data in dict2.keys():\n",
    "        x1.append(data)\n",
    "    for data in dict2.values():\n",
    "        y1.append(data)\n",
    "        \n",
    "    # plot accuracy with respect to 3 cases \n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(1,1,figsize=(8,5))\n",
    "    opacity = .7\n",
    "    w = .3\n",
    "    \n",
    "    a1 = [x for x, _ in enumerate(x)]\n",
    "    b1 = [x + w for x in a1]\n",
    "\n",
    "    axs.bar(a1, y, color='red', width=w, edgecolor='white', label='Bimodal')\n",
    "    axs.bar(b1, y1, color='yellowgreen', width=w, edgecolor='white', label='One modal')\n",
    "\n",
    "    plt.xticks([x + w for x in range(len(x))], x)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('Three Cases of Discriminant Analysis')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Performance Analysis of Bimodal & One modal Gaussian Distributions \\n with Prior Probability 0.5 Each')\n",
    "    plt.show()\n",
    "\n",
    "# uncomment this line for output\n",
    "# plot_modal (bimodal_dict,unimodal_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
