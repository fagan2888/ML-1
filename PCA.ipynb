{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change 'yes' and 'no' to 1 and 0 indicating 'with disease' and 'without disease'.\n",
    "def preprocessing(filename):\n",
    "    fileData = open(filename, \"r\",encoding='utf-8-sig')\n",
    "    lines = fileData.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        data.append(x)\n",
    "    headers = data.pop(0) # gives the headers as list and leaves data\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df['type'] = df['type'].map({'Yes': 1, 'No': 0})\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    return df\n",
    "\n",
    "# calculate mean and variance for the dataframe\n",
    "def train_mean_std(data):\n",
    "    mean = data.mean ()\n",
    "    std = data.std()\n",
    "    return mean,std\n",
    "\n",
    "# normalize the dataset\n",
    "def normalize (data,mean,std):\n",
    "    normalized_data = (data - mean)/std\n",
    "    d = data[['type']].copy()\n",
    "    cls = d['type']\n",
    "    normalized_data ['type'] = cls\n",
    "    return normalized_data\n",
    "\n",
    "# save it to a text file for further use\n",
    "def save_df (df,filename,fmt):\n",
    "    col = len (df.columns)\n",
    "    X = df.iloc[:,0:col].values\n",
    "    Y = np.matrix(X)    \n",
    "    np.savetxt(filename,Y,fmt)\n",
    "    \n",
    "# for training data\n",
    "preprocessed_train = preprocessing ('PIMA.TR')\n",
    "mean,std = train_mean_std (preprocessed_train)\n",
    "norm_train = normalize (preprocessed_train,mean,std)\n",
    "# print (norm_train)\n",
    "\n",
    "# for testing data\n",
    "preprocessed_test = preprocessing ('PIMA.TE')\n",
    "norm_test = normalize (preprocessed_test,mean,std)\n",
    "save_df (norm_train,'nX_PIMA_TR.txt','%.6f')\n",
    "save_df (norm_test, 'nX_PIMA_TE.txt','%.6f')\n",
    "# ### all of this can be done by using list or matrix. I have used dataframe to avoid complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check with sklearn if the normalization is correct\n",
    "# from sklearn import preprocessing\n",
    "# # Get column names first\n",
    "# names = preprocessed_train.columns\n",
    "# # Create the Scaler object\n",
    "# scaler = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# # Fit your data on the scaler object\n",
    "# scaled_df = scaler.fit_transform(preprocessed_train)\n",
    "# scaled_df = pd.DataFrame(scaled_df, columns=names)\n",
    "# scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the raw train and test data\n",
    "def visualize_raw_data(data):\n",
    "    headers = data.columns.tolist()\n",
    "    n = len(headers)\n",
    "    f, ax = plt.subplots(1, n, figsize=(10,3))\n",
    "    for i in range (0,n):\n",
    "        vis1 = sns.distplot(data[headers[i]],bins=10, ax= ax[i])\n",
    "    sns.pairplot(data, hue=\"type\")\n",
    "    \n",
    "# visualize_raw_data (preprocessed_train)    \n",
    "# visualize_raw_data (preprocessed_test)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate covariance and perform eigenvalue decomposition\n",
    "def basis(data):\n",
    "    np.set_printoptions(formatter={'float':\"{:6.20g}\".format})\n",
    "\n",
    "    col = len (data.columns)-1\n",
    "    X = data.iloc[:,0:col].values\n",
    "    y = data.iloc[:,col].values\n",
    "    mat_X = np.matrix(X)    \n",
    "    mu = mat_X.sum(axis = 0)/(len(mat_X)) \n",
    "    mean = np.matrix(mu).T\n",
    "    cls = np.matrix(y).T\n",
    "\n",
    "    covariance_mat = (mat_X - mu).T.dot((mat_X - mu))/(mat_X.shape[0]-1)\n",
    "    e_values, e_vectors = np.linalg.eig(covariance_mat)\n",
    "    e_pairs = [(np.abs(e_values[i]), e_vectors[:,i]) for i in range(len(e_values))]\n",
    "\n",
    "    # sort from high to low\n",
    "    e_pairs.sort()\n",
    "    e_pairs.reverse()\n",
    "    e_val_mat = np.asmatrix(e_values)\n",
    "    # sort the eigenvalue in the ascending order\n",
    "    e_val_mat.sort()\n",
    "\n",
    "    return mat_X, e_vectors, e_val_mat, e_pairs, cls, e_values\n",
    "\n",
    "mat_X, e_vectors, e_val_mat, e_pairs, cls, e_values= basis (norm_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# derive a new set of basis and choose the major axes with variable error rate\n",
    "def PCA(eigen_val_mat,eigen_pairs,normalized_data,error_rate):\n",
    "    psum = 0.0\n",
    "    nf = np.size(eigen_val_mat,1)\n",
    "    for i in range (0, nf):\n",
    "        psum += eigen_val_mat[0, i]\n",
    "    p = 0\n",
    "    sum = 0.0\n",
    "    while sum/psum < error_rate and p < nf:\n",
    "        sum += eigen_val_mat[0,p]\n",
    "        p += 1   \n",
    "    pnf = nf - (p-1)  \n",
    "    matrix_w = np.hstack((eigen_pairs[i][1].reshape(nf,1))for i in range (0,pnf))\n",
    "    return matrix_w\n",
    "\n",
    "# Represent the data using this new set of basis for a reduced dimension\n",
    "def dimension_reduction(W, data):\n",
    "    col = len (data.columns)-1\n",
    "    x = data.iloc[:,0:col].values\n",
    "    y = data['type'].values\n",
    "    mat = np.matrix(x)\n",
    "    classs = np.matrix(y).T\n",
    "\n",
    "    reduced_data = (mat.dot(W))\n",
    "    pX = np.hstack((reduced_data.real,classs))\n",
    "#     print ('\\n Reduced Data: \\n', pX)\n",
    "    return pX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = PCA (e_val_mat,e_pairs,mat_X,.10)\n",
    "\n",
    "pX = dimension_reduction (W, norm_train )\n",
    "pX1 = dimension_reduction (W, norm_test )\n",
    "\n",
    "np.savetxt('pX_PIMA_TR.txt',pX,fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TE.txt',pX1,fmt='%.4f')\n",
    "\n",
    "\n",
    "# PCA (eigVal,eig_pairs,mat,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for variable error rate (eigenvalues from 1 to 7)\n",
    "def PCA_error_rate(PCA_error_rate,eig_pairs,mat,data1,data2):\n",
    "    error = [.01,.05,.1,.2,.4,.5,.7]\n",
    "    pX = []\n",
    "    pX_test = []\n",
    "    for e in error:\n",
    "        W = PCA (eigen_val_mat,eigen_pairs,mat_X,e)\n",
    "        pX.append(dimension_reduction (W, data1))\n",
    "        pX_test.append(dimension_reduction (W, data2))\n",
    "#         print (W)    \n",
    "    return pX,pX_test\n",
    "\n",
    "pX,pX1 = PCA_error_rate(PCA_error_rate,eig_pairs,mat,norm_train,norm_test)\n",
    "np.savetxt('pX_PIMA_TR_0.01.txt',pX[0],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TR_0.05.txt',pX[1],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TR_0.1.txt',pX[2],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TR_0.2.txt',pX[3],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TR_0.4.txt',pX[4],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TR_0.5.txt',pX[5],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TR_0.7.txt',pX[6],fmt='%.4f')\n",
    "\n",
    "np.savetxt('pX_PIMA_TE_0.01.txt',pX1[0],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TE_0.05.txt',pX1[1],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TE_0.1.txt',pX1[2],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TE_0.2.txt',pX1[3],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TE_0.4.txt',pX1[4],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TE_0.5.txt',pX1[5],fmt='%.4f')\n",
    "np.savetxt('pX_PIMA_TE_0.7.txt',pX1[6],fmt='%.4f')\n",
    "\n",
    "# np.savetxt('pX_PIMA_TE.txt',pX1,fmt='%.4f')\n",
    "\n",
    "\n",
    "# PCA (eigVal,eig_pairs,mat,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## use built in PCA from sklearn to check with the model accuracy\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=6)\n",
    "# principalComponents = pca.fit_transform(norm_train)\n",
    "# principalDf = pd.DataFrame(data = principalComponents\n",
    "#              , columns = ['1', '2','3','4','5','6'])\n",
    "\n",
    "# principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
