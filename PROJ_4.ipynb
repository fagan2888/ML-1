{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all packages\n",
    "import operator\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "def loadDataset (trainfile):\n",
    "    fileData = open(trainfile, \"r\",encoding='utf-8-sig')\n",
    "    lines = fileData.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        data.append(x)\n",
    "    \n",
    "    df = pd.DataFrame(data,index = None)\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    df1 = df.apply(lambda x: pd.Series(x.dropna().values))\n",
    "\n",
    "    trainingSet = df1.values.tolist()\n",
    "    \n",
    "    return trainingSet\n",
    "\n",
    "trainingSet = loadDataset('FGLASS.DAT')\n",
    "norm_train_ = pd.DataFrame(trainingSet)\n",
    "\n",
    "# normalizing data\n",
    "def preprocessing(filename):\n",
    "    trainingSet = loadDataset(filename)\n",
    "    df = pd.DataFrame(trainingSet, columns = ['A','B','C','D','E','F','G','H','I','type'])\n",
    "    return df\n",
    "\n",
    "# calculate mean and variance for the dataframe\n",
    "def train_mean_std(data):\n",
    "    mean = data.mean ()\n",
    "    std = data.std()\n",
    "    return mean,std\n",
    "\n",
    "# normalize the dataset\n",
    "def normalize (data,mean,std):\n",
    "    normalized_data = (data - mean)/std\n",
    "    d = data[['type']].copy()\n",
    "    cls = d['type']\n",
    "    normalized_data ['type'] = cls\n",
    "    return normalized_data\n",
    "\n",
    "# save it to a text file for further use\n",
    "def save_df (df,filename,fmt):\n",
    "    col = len (df.columns)\n",
    "    X = df.iloc[:,0:col].values\n",
    "    Y = np.matrix(X)    \n",
    "    np.savetxt(filename,Y,fmt)\n",
    "    \n",
    "preprocessed_train = preprocessing ('FGLASS.DAT')\n",
    "mean,std = train_mean_std (preprocessed_train)\n",
    "norm_train = normalize (preprocessed_train,mean,std)\n",
    "# print (norm_train)\n",
    "\n",
    "save_df (norm_train,'fglass.txt','%.6f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Euclidean distances \n",
    "def euclidean_distance(test_sample, train_set, length):\n",
    "    d = 0\n",
    "    for i in range(length):\n",
    "        d += np.square(test_sample[i] - train_set[i])\n",
    "    return np.sqrt(d)\n",
    "\n",
    "#select neighbors based on calculation\n",
    "def neighbors(training_set, test_sample, K):\n",
    "    d_set = []\n",
    "    n = len(test_sample)-1\n",
    "    for x in range(len(training_set)):\n",
    "        distance = euclidean_distance(test_sample, training_set[x], n)\n",
    "        d_set.append((training_set[x], distance))\n",
    "    d = sorted(d_set, key=itemgetter(1))\n",
    "    neighbor_set = []\n",
    "    for k in range(K):\n",
    "        neighbor_set.append(d[k][0])\n",
    "    return neighbor_set\n",
    "\n",
    "# get most frequent element from a list\n",
    "def most_frquent (List):\n",
    "    return max(set(List),key=List.count)\n",
    "    \n",
    "# classify test data\n",
    "def classification(neighbors):\n",
    "    classs = []\n",
    "    for neigh in neighbors:\n",
    "        vote = neigh[len(neigh)-1]\n",
    "        classs.append(vote)\n",
    "    return most_frquent(classs)\n",
    "\n",
    "#run KNN altogether for predictions\n",
    "def kNN(training_set,test_set,K):\n",
    "    prediction=[]\n",
    "    for x in range(len(test_set)):\n",
    "        neighbor_data = neighbors(training_set, test_set[x], K)\n",
    "        result = classification(neighbor_data)\n",
    "        prediction.append(result)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# calculate accuracy\n",
    "def kNN_accuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "# calculate accuracy for diffrent K\n",
    "def vary_k(trainingSet,testSet):\n",
    "    K = [x for x in range (1,16)]\n",
    "    K.append(int(np.sqrt(len(trainingSet))))\n",
    "    K = (np.unique(np.array(K))).tolist()\n",
    "    accuracy = []\n",
    "    for k in K:\n",
    "        predictions = kNN(trainingSet,testSet,k)\n",
    "        acc = kNN_accuracy (testSet, predictions)    \n",
    "        accuracy.append(acc)\n",
    "    return K, accuracy\n",
    "\n",
    "# vary_k (trainingSet,testSet,1)\n",
    "\n",
    "# flatten list\n",
    "def flatten(l): \n",
    "    return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold validation on the training set\n",
    "# split the training set into train and test based on given index\n",
    "def indexwise_train_test_split (filename):\n",
    "    fileData = open(filename, \"r\",encoding='utf-8-sig')\n",
    "    lines = fileData.readlines()\n",
    "    index = []\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        y = [int(y)-1 for y in x]\n",
    "        index.append(y)\n",
    "    index_ = []\n",
    "    for i in range(len(index)):\n",
    "        y1 = [index[i]]\n",
    "        x1 = list(chain(*[j for j in index if j not in y1]))\n",
    "        index_.append([x1,y1[0]])\n",
    "        \n",
    "    return index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39efb726fb754033a1790814e8bd7ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get mean accuracy of all K-folds for diffrent k in kNN\n",
    "def cross_validation_score(train,n_folds):\n",
    "    col = len (train.columns)\n",
    "    X = train.iloc[:,0:col].values\n",
    "    \n",
    "    acc = []\n",
    "    max_acc = []\n",
    "    mean_k = []\n",
    "    \n",
    "    index = indexwise_train_test_split ('FGLASS.GRP')\n",
    "\n",
    "    for train_index, test_index in tqdm_notebook(index):\n",
    "        x = X[train_index]\n",
    "        y = X[test_index]\n",
    "        K, ac = vary_k(x,y)\n",
    "        acc.append(ac) \n",
    "    mean_all_k = []\n",
    "    std_acc = []\n",
    "    for k in range(len(K)):\n",
    "        summ = 0\n",
    "        acc_k = []\n",
    "        for i in range (n_folds):\n",
    "            summ+=acc[i][k]\n",
    "            acc_k.append(acc[i][k])\n",
    "        max_acc.append(max(acc_k))\n",
    "        std_acc.append((np.array(acc_k)).std())\n",
    "        mean_all_k.append(summ/n_folds)\n",
    "\n",
    "    return mean_all_k,std_acc,K,max_acc\n",
    "\n",
    "\n",
    "accuracy,std_acc,K,max_acc = cross_validation_score(norm_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot validation accuracy with classification accuracy\n",
    "def kNN_validation_plot(accuracy,std_acc,max_acc,K):\n",
    "    plt.figure(figsize=(8,7))\n",
    "    plt.plot(K, max_acc,'ro-',lw = 1,label = \"best accuracy for each k\")\n",
    "    plt.errorbar(K, accuracy, np.array(std_acc),\n",
    "                 color = 'b',marker = 'o',lw = 1,label = 'cross-validation accuracy for k = [1,15]')\n",
    "    plt.errorbar(K[13], accuracy[13],np.array(std_acc[13]),\n",
    "                 color = 'darkorange',marker = '*',markersize = 10, lw = 1,label = 'cross-validation accuracy for k = sqrt(n)')     \n",
    "    plt.xlabel('k values')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend (loc = 'best')\n",
    "    plt.title('Performance Curve for Different k values')\n",
    "    plt.show()\n",
    "    \n",
    "# kNN_validation_plot(accuracy,std_acc,max_acc,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check kNN result with scikit learn\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# def KNN_scikit(train,n_fold):\n",
    "#     col = len (train.columns)\n",
    "#     X = train.iloc[:,0:col].values\n",
    "\n",
    "#     index = indexwise_train_test_split ('FGLASS.GRP')\n",
    "#     mean_k = []\n",
    "#     K = [x for x in range (1,15)]\n",
    "#     K.append(int(np.sqrt(len(train))))\n",
    "\n",
    "#     for k in range (1,len(K)+1):\n",
    "#         accuracy = 0\n",
    "#         for train_index, test_index in index:\n",
    "\n",
    "#             x = X[train_index]\n",
    "#             X_train  = x[:,:col-1]\n",
    "#             y_train = x[:,col-1]\n",
    "\n",
    "#             x = X[test_index]\n",
    "#             X_test  = x[:,:col-1]\n",
    "#             y_test = x[:,col-1]\n",
    "\n",
    "#             clf = KNeighborsClassifier(n_neighbors = k, weights='uniform', algorithm='auto')\n",
    "#             clf.fit(X_train, y_train) \n",
    "\n",
    "#             y_pred = clf.predict(X_test)\n",
    "#             accuracy += accuracy_score(y_test,y_pred)*100\n",
    "            \n",
    "#         avg = accuracy/n_fold\n",
    "#         print (\"Accuracy is \",avg ,\"%\")\n",
    "#         mean_k.append(avg)\n",
    "#     return mean_k\n",
    "\n",
    "# KNN_scikit(norm_train,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement DT using sk-learn\n",
    "def decision_tree(train):\n",
    "    col = len (train.columns)\n",
    "    X = train.iloc[:,0:col].values\n",
    "    accuracy = []\n",
    "    index = indexwise_train_test_split ('FGLASS.GRP')\n",
    "    for train_index, test_index in index:\n",
    "        \n",
    "        train = X[train_index]\n",
    "        X_train  = train[:,:col-1]\n",
    "        y_train = train[:,col-1]\n",
    "\n",
    "        test = X[test_index]\n",
    "        X_test  = test[:,:col-1]\n",
    "        y_test = test[:,col-1]\n",
    "        \n",
    "        clf = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                          max_depth=None, min_samples_split=8, \n",
    "                                          min_samples_leaf=4, min_weight_fraction_leaf=0.0, \n",
    "                                          max_features=None, random_state=0, \n",
    "                                          max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                          min_impurity_split=None, class_weight=None, presort=True)\n",
    "        clf.fit(X_train, y_train) \n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test,y_pred)*100\n",
    "        accuracy.append(acc)\n",
    "#         print (\"Accuracy is \", acc,\"%\\n\")\n",
    "    return (sum(accuracy)/len(accuracy)),accuracy\n",
    "\n",
    "# avg,acc = decision_tree(norm_train_)\n",
    "# print ('Validation Accuracy: ',avg)\n",
    "\n",
    "#better accuracy for min_samples_leaf = 2 than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "def DT_accuracy_plot(accuracy,folds):\n",
    "    plt.figure(figsize=(8,7))\n",
    "    plt.plot(folds, accuracy,'bo-',lw = 1)\n",
    "    plt.xlabel('Folds')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Performance Curve for Different Folds')\n",
    "    plt.show()\n",
    "\n",
    "folds = []\n",
    "for i in list(range(1,11)):\n",
    "    folds.append('Fold'+str(i))\n",
    "\n",
    "# DT_accuracy_plot(acc,folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexwise_train_test_val_split (filename,n):\n",
    "    fileData = open(filename, \"r\",encoding='utf-8-sig')\n",
    "    lines = fileData.readlines()\n",
    "    index = []\n",
    "    for line in lines:\n",
    "        x = line.split()\n",
    "        y = [int(y)-1 for y in x]\n",
    "        index.append(y)\n",
    "    test = [index[n]]\n",
    "    val = [index[n-1]]\n",
    "    test_val = test+val\n",
    "    train = list(chain(*[j for j in index if j not in test_val]))\n",
    "    index_ = [train,test[0],val[0]]\n",
    "    return index_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement MLP\n",
    "def NN(train,solver,activation_function):\n",
    "    n_folds = 10\n",
    "    n_nodes = list (range (2,16))\n",
    "    col = len (train.columns)\n",
    "    X = train.iloc[:,0:col].values\n",
    "\n",
    "    accuracy_test = []\n",
    "    accuracy_val = []\n",
    "    \n",
    "    plt.figure(figsize=(8,7))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('solver: '+solver+' & '+'activation_function: '+activation_function)\n",
    "    \n",
    "    for n in n_nodes:\n",
    "        print ('Number of Nodes: ',n)\n",
    "        test_acc = 0.0\n",
    "        val_acc = 0.0\n",
    "        clf_ = []\n",
    "        for i in list(range(0,n_folds)):\n",
    "            index = indexwise_train_test_val_split ('FGLASS.GRP',i)\n",
    "            train_ind = index[0]\n",
    "            val_ind = index[2]\n",
    "            test_ind = index[1]\n",
    "            train_val_ind = flatten([train_ind,val_ind])\n",
    "\n",
    "            train = X[train_val_ind]\n",
    "            X_train  = train[:,:col-1]\n",
    "            y_train = train[:,col-1]\n",
    "\n",
    "            test = X[test_ind]\n",
    "            X_test  = test[:,:col-1]\n",
    "            y_test = test[:,col-1]\n",
    "\n",
    "            val = X[val_ind]\n",
    "            X_val  = val[:,:col-1]\n",
    "            y_val = val[:,col-1]\n",
    "            clf = MLPClassifier(solver=solver,activation=activation_function,\n",
    "                                hidden_layer_sizes=(n,),shuffle= False,\n",
    "                                random_state = 0,validation_fraction = .1,max_iter = 1000) \n",
    "            clf = clf.fit(X_train, y_train)\n",
    "            clf_.append(clf)\n",
    "            y_pred_test = clf.predict (X_test)\n",
    "            test_acc += accuracy_score(y_test,y_pred_test)*100\n",
    "            \n",
    "\n",
    "            y_pred_val = clf.predict (X_val)\n",
    "            val_acc += accuracy_score (y_val,y_pred_val)*100\n",
    "        plt.plot(clf_[0].loss_curve_,label = n)\n",
    "        plt.legend(loc = 'best')\n",
    "        print ('Testing Accuracy: ',test_acc/n_folds,'%')\n",
    "        print ('Validation Accuracy: ',val_acc/n_folds,'%')\n",
    "        accuracy_test.append(test_acc/n_folds)\n",
    "        accuracy_val.append(val_acc/n_folds)\n",
    "    return accuracy_test,accuracy_val,n_nodes\n",
    "\n",
    "preprocessed_train = preprocessing ('FGLASS.DAT')\n",
    "mean,std = train_mean_std (preprocessed_train)\n",
    "norm_train = normalize (preprocessed_train,mean,std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_accuracy_plot(accuracy_test,accuracy_val,n_nodes):\n",
    "    plt.figure(figsize=(8,7))\n",
    "    line1 = plt.plot(n_nodes, accuracy_val,'bo-',lw = 1,label = \"validation accuracy\")\n",
    "    line2 = plt.plot(n_nodes, accuracy_test,'ro-',lw = 1,label = \"testing accuracy\")\n",
    "    plt.xlabel('Number of Hidden Nodes')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend (loc = 'best')\n",
    "    plt.title('Performance Curve for Different Number of Nodes')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy_test,accuracy_val,n_nodes = NN(norm_train,'adam','relu')\n",
    "# NN_accuracy_plot(accuracy_test,accuracy_val,n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy_test,accuracy_val,n_nodes = NN(norm_train,'adam','logistic')\n",
    "# NN_accuracy_plot(accuracy_test,accuracy_val,n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_test,accuracy_val,n_nodes = NN(norm_train,'sgd','relu')\n",
    "# NN_accuracy_plot(accuracy_test,accuracy_val,n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy_test,accuracy_val,n_nodes = NN(norm_train,'sgd','logistic')\n",
    "# NN_accuracy_plot(accuracy_test,accuracy_val,n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arbitrary m-fold train-validation set split (by not using index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test data arbitrarily\n",
    "def arbitrary_train_test_split(n_split, x_len):\n",
    "    index = []\n",
    "    test_size = int(x_len/n_split)\n",
    "    train_size = x_len - test_size\n",
    "    for i in range(n_split):\n",
    "        j = i*test_size\n",
    "        index.append([list(set(list(range(0,x_len))).difference(set(list(range(j,j+test_size)))) ),\n",
    "                     list(range(j,j+test_size))])\n",
    "    return index\n",
    "\n",
    "#get mean accuracy of all K-folds for diffrent k in KNN\n",
    "def cross_validation_score(trainingSet, n_split,prior0):\n",
    "    train = pd.DataFrame(trainingSet)\n",
    "    col = len (train.columns)\n",
    "    X = train.iloc[:,0:col].values\n",
    "    index = arbitrary_train_test_split(n_split, len(X))\n",
    "    acc = []\n",
    "    mean_k = []\n",
    "    \n",
    "    for train_index, test_index in index:\n",
    "        x = X[train_index]\n",
    "        y = X[test_index]\n",
    "        K, ac = vary_k(x,y,prior0)\n",
    "        acc.append(ac) \n",
    "    for k in range(len(K)):\n",
    "        avg = (acc[0][k]+acc[1][k]+acc[2][k]+acc[3][k]+acc[4][k])/5\n",
    "        mean_k.append(avg)\n",
    "\n",
    "    return mean_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
